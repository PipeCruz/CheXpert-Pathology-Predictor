{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# training data\n",
    "# training data loader\n",
    "\n",
    "# testing data\n",
    "# testing data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'cs156b\\cs156b_train_data_small' # change if necessary\n",
    "csv_file = pd.read_csv('cs156b/train2023.csv')\n",
    "\n",
    "df = csv_file\n",
    "\n",
    "y_cols = ['No Finding', 'Enlarged Cardiomediastinum', \n",
    "            'Cardiomegaly', 'Lung Opacity', 'Pneumonia', \n",
    "            'Pleural Effusion', 'Pleural Other', 'Fracture', \n",
    "            'Support Devices']\n",
    "\n",
    "# why are we doing this filling of NaN values to be 0?\n",
    "csv_file[y_cols] = csv_file[y_cols].fillna(0)\n",
    "\n",
    "# df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "Y = df[y_cols]\n",
    "\n",
    "X = df[\"Path\"]\n",
    "\n",
    "print(X[:5],Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!  pip install imageio-ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"My custom chexpert dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the CSV file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "                defaults to /groups/CS156b/data\n",
    "                where we have images in data/train and data/test\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        # fil in NaN values with 0\n",
    "        self.df[y_cols] = self.df[y_cols].fillna(0)\n",
    "        \n",
    "        # self.root_dir = root_dir\n",
    "        # self.root_dir = \"/groups/CS156b/data\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "                   \n",
    "        # I want to get a sample and the sample should be the Path that corresponds to the idx which is the first column\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        \n",
    "        \n",
    "        path = row['Path']\n",
    "        path = path[6:]\n",
    "        \n",
    "        try:\n",
    "            image_np = io.imread(os.path.join(self.root_dir, path), as_gray=True)\n",
    "    \n",
    "            # Apply transformations if needed\n",
    "            if self.transform:\n",
    "                image_pil = Image.fromarray(image_np)\n",
    "                image_pil = self.transform(image_pil)\n",
    "                image_np = np.array(image_pil)\n",
    "\n",
    "            image = torch.tensor(image_np, dtype=torch.float32)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"failed: \", e)\n",
    "            # image is 224 x 224 in grayscale\n",
    "            # to float tensor\n",
    "            image = torch.zeros(1, 224, 224, dtype=torch.float32)\n",
    "            \n",
    "        # Convert labels to numpy array\n",
    "        labels = row[y_cols].values\n",
    "        \n",
    "        labels = labels.astype(np.float32)\n",
    "\n",
    "\n",
    "        # Convert numpy array to tensor, specifying the dtype as torch.float32\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "\n",
    "            \n",
    "        return image, labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect images that I have rn on my pc\n",
    "# fixme this shouldn't matter for hpc but will need to remove code\n",
    "idxs = []\n",
    "for i in range(1, 501):\n",
    "    # zfill for 5 digits\n",
    "    stri = str(i).zfill(5)\n",
    "    # print the idx of which \"Path\" has \"pid{stri}\"\n",
    "    mask = df[\"Path\"].fillna(\"\").str.contains(f\"pid{stri}\")\n",
    "    # print(f\"pid{stri} is at index {df[mask].index}\")\n",
    "    for j in df[mask].index:\n",
    "        idxs.append(j)\n",
    "        \n",
    "print(idxs)\n",
    "len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models.resnet import ResNet18_Weights, BasicBlock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# customset = CustomDataset(csv_file='cs156b/train2023.csv', root_dir='cs156b/cs156b_train_data_small', )\n",
    "from torchvision.transforms import Grayscale\n",
    "\n",
    "# copilot\n",
    "transformations = Compose([\n",
    "    Grayscale(num_output_channels=1),\n",
    "    Resize((224, 224)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Create the dataset with the transformations\n",
    "customset = CustomDataset(csv_file='cs156b/train2023.csv', root_dir='cs156b/cs156b_train_data_small', transform=transformations)\n",
    "\n",
    "subset = torch.utils.data.Subset(customset, idxs)\n",
    "\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(subset))\n",
    "test_size = len(subset) - train_size\n",
    "# in the meantime, while I don't have the whole set\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(subset, [train_size, test_size])\n",
    "\n",
    "# set batch size\n",
    "batch_size = 32\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "train_features, train_labels = next(iter(train_data_loader))\n",
    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "# print(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for img, lab in subset:\n",
    "    # show 10 imgs\n",
    "    plt.imshow(img.squeeze(0), cmap='gray')\n",
    "    plt.show()\n",
    "    if j == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load pre-trained ResNet\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Use CUDA if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the CUDA device\n",
    "\n",
    "\n",
    "# Change the first layer to accept grayscale images\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "\n",
    "# Change the number of output features of the last layer\n",
    "num_classes = 9 \n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move the criterion to the CUDA device\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming train_data_loader is your DataLoader for training data\n",
    "\n",
    "losses = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for _ in tqdm(range(15)):\n",
    "    for images, labels in train_data_loader:\n",
    "        # Move images and labels to the CUDA device\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "    losses.append(loss.item())\n",
    "\n",
    "\n",
    "# plot loss\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test_data printing side by side\n",
    "\n",
    "model.eval()\n",
    "\n",
    "losses2 = []\n",
    "\n",
    "for images, labels in test_data_loader:\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    output = model(images)\n",
    "    print(\"Predictions:\")\n",
    "    print(output)\n",
    "    print(\"True labels:\")\n",
    "    print(labels)\n",
    "    loss = criterion(output, labels)\n",
    "    \n",
    "    \n",
    "    losses2.append(loss.item())\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Open the CSV file\n",
    "with open(\"predictions.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    for images, labels in test_data_loader:\n",
    "        images = images.cuda()\n",
    "        output = model(images)\n",
    "        # Convert the predictions to a numpy array and write them to the CSV file\n",
    "        writer.writerows(output.cpu().detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
